{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 17:25:21.352684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-12 17:25:21.395604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-12 17:25:21.395857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import random\n",
    "import math\n",
    "import helper\n",
    "import importlib\n",
    "import h5py\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras import backend as keras_backend\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, SpatialDropout2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# set the random seed\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "#MFCC_RESNET32_lr-1e-06_b1-0.99_b2-0.999_EPOCH-500_BATCH-32_cc_v3.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_dir = os.path.join(\"/home/charlesedwards/Documents\", 'kaggle_2018_dataset')\n",
    "data_npy_folder = os.path.join(dataset_root_dir, 'data')\n",
    "\n",
    "# get the train and test data directories\n",
    "train_dir = os.path.join(dataset_root_dir, 'train')\n",
    "test_dir = os.path.join(dataset_root_dir, 'test')\n",
    "\n",
    "# get the catalog.csv for train and test directories\n",
    "train_catalog_csv = os.path.join(train_dir, 'catalog.csv')\n",
    "test_catalog_csv = os.path.join(test_dir, 'catalog.csv')\n",
    "\n",
    "# read the catalog.csv files\n",
    "train_metadata = pd.read_csv(train_catalog_csv)\n",
    "test_metadata = pd.read_csv(test_catalog_csv)\n",
    "\n",
    "# drop unwanted columns \n",
    "test_metadata.drop(['license','freesound_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in pre-processed MFCC train data\n",
    "#X_train = np.load( os.path.join(data_npy_folder, \"X-mfcc-train.npy\" ) )\n",
    "#y_train = np.load( os.path.join(data_npy_folder, \"y-mel-train.npy\" ) )\n",
    "\n",
    "# load in pre-processed MFCC train data\n",
    "#X_test = np.load( os.path.join(data_npy_folder, \"X-mfcc-test.npy\" ) )\n",
    "#y_test = np.load( os.path.join(data_npy_folder, \"y-mel-test.npy\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/charlesedwards/Documents/kaggle_2018_dataset/models/V3/RESNET/MFCC_RESNET32_lr-1e-06_b1-0.99_b2-0.999_EPOCH-500_BATCH-32_cc_v3.h5'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = os.path.join( dataset_root_dir, 'models')\n",
    "model_dir = os.path.join( model_dir, 'V3/RESNET')\n",
    "model_dir = os.path.join( model_dir, 'MFCC_RESNET32_lr-1e-06_b1-0.99_b2-0.999_EPOCH-500_BATCH-32_cc_v3.h5')\n",
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 40#128#40\n",
    "sampling_rate = 44100\n",
    "audio_duration = 2\n",
    "audio_length = audio_duration * sampling_rate\n",
    "input_shape = (n_mfcc, 1 + int(np.floor(audio_length/512)), 1)\n",
    "\n",
    "def prepare(file_path:str):\n",
    "\n",
    "    # using librosa to load the wav file\n",
    "    y, sr = librosa.load(file_path,duration=audio_duration)#audio_duration) # ,duration=5\n",
    "\n",
    "    # normalize the audio with librosa\n",
    "    y = librosa.util.normalize(y)\n",
    "\n",
    "    # Extract MFCC data\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "\n",
    "    # normalize the mfcc between -1 and 1\n",
    "    #mfcc = librosa.util.normalize(mfcc)\n",
    "\n",
    "    # reshape for neural network\n",
    "    array = np.resize(mfcc, input_shape)\n",
    "    return array.reshape(1, array.shape[0], array.shape[1], array.shape[2])\n",
    "\n",
    "\n",
    "# def prepare2(file_path:str):\n",
    "\n",
    "#     # using librosa to load the wav file\n",
    "#     y, sr = librosa.load(file_path,duration=audio_duration)#audio_duration) # ,duration=5\n",
    "\n",
    "#     # normalize the audio with librosa\n",
    "#     y = librosa.util.normalize(y)\n",
    "\n",
    "#     # generate a mel scaled spectrogram\n",
    "#     mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr) # n_mels=n_mels\n",
    "\n",
    "#     # convert the sound intensity to log scale\n",
    "#     mel_db = librosa.amplitude_to_db(np.abs(mel_spectrogram))\n",
    "\n",
    "#     # normalize the data to 0-1\n",
    "#     normalized_mel = librosa.util.normalize(mel_db)\n",
    "\n",
    "#     # # Extract MFCC data\n",
    "#     # mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "\n",
    "#     # # normalize the mfcc between -1 and 1\n",
    "#     # mfcc = librosa.util.normalize(mfcc)\n",
    "\n",
    "#     # reshape for neural network\n",
    "#     array = np.resize(normalized_mel, input_shape)\n",
    "#     return array.reshape(1, array.shape[0], array.shape[1], array.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bark -> Cough\n"
     ]
    }
   ],
   "source": [
    "sample = test_metadata.sample()\n",
    "wav_dir_of_sample = os.path.join(test_dir, sample['fname'].values[0])\n",
    "\n",
    "# get prediction\n",
    "predictions = model.predict([prepare(wav_dir_of_sample)])\n",
    "\n",
    "labels = list(train_metadata['label'].unique())\n",
    "\n",
    "index = np.argmax(predictions, axis=None, out=None)#np.argmax(predictions)\n",
    "print(f\"{sample['label'].values[0]} -> {labels[index]}\")\n",
    "#len(predictions.tolist()[0]), len(labels), index\n",
    "#predictions.tolist()[0][index], predictions.tolist()[0], labels[index]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
