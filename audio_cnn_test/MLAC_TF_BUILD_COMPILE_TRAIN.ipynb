{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning: TF Audio Classification Model Creation and Training Evaluation Document\n",
    "In this document we will read in our feature npy files, construct, train and evaluate a model for audio classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "from netplot import ModelPlot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFCC CNN\n",
    "In this section we will construct our MFCC CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os path to desktop\n",
    "desktop_path = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "\n",
    "dataset_root_dir = os.path.join(desktop_path, 'kaggle_2018_dataset')\n",
    "data_npy_folder = os.path.join(dataset_root_dir, 'data')\n",
    "\n",
    "# load the training data\n",
    "dataset_train_folder = os.path.join(dataset_root_dir, 'train')\n",
    "dataset_train_csv = os.path.join(dataset_train_folder, 'catalog.csv')\n",
    "\n",
    "# load in our data_frame\n",
    "metadata = pd.read_csv(dataset_train_csv)\n",
    "\n",
    "# Pre-processed MFCC coefficients\n",
    "X = np.load( os.path.join(data_npy_folder, \"X-mfcc.npy\" ) )\n",
    "y = np.load( os.path.join(data_npy_folder, \"y-mfcc.npy\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split: 1894 \t\t Train split: 7579\n",
      "X test shape: (1894, 40, 2584) \t X train shape: (7579, 40, 2584)\n",
      "y test shape: (1894,) \t\t y train shape: (7579,)\n"
     ]
    }
   ],
   "source": [
    "# create train and test sets\n",
    "indexes = []\n",
    "total = len(metadata)\n",
    "indexes = list(range(0, total))\n",
    "\n",
    "# Randomize indexes\n",
    "random.shuffle(indexes)\n",
    "\n",
    "# Divide the indexes into Train and Test\n",
    "test_split_pct = 20\n",
    "split_offset = math.floor(test_split_pct * total / 100)\n",
    "\n",
    "# Split the metadata\n",
    "test_split_idx = indexes[0:split_offset]\n",
    "train_split_idx = indexes[split_offset:total]\n",
    "\n",
    "# Split the features with the same indexes\n",
    "X_test = np.take(X, test_split_idx, axis=0)\n",
    "y_test = np.take(y, test_split_idx, axis=0)\n",
    "X_train = np.take(X, train_split_idx, axis=0)\n",
    "y_train = np.take(y, train_split_idx, axis=0)\n",
    "\n",
    "# Also split metadata\n",
    "test_meta = metadata.iloc[test_split_idx]\n",
    "train_meta = metadata.iloc[train_split_idx]\n",
    "\n",
    "# Print status\n",
    "print(\"Test split: {} \\t\\t Train split: {}\".format(len(test_meta), len(train_meta)))\n",
    "print(\"X test shape: {} \\t X train shape: {}\".format(X_test.shape, X_train.shape))\n",
    "print(\"y test shape: {} \\t\\t y train shape: {}\".format(y_test.shape, y_train.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras import backend as keras_backend\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, SpatialDropout2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_test_encoded = to_categorical(le.fit_transform(y_test))\n",
    "y_train_encoded = to_categorical(le.fit_transform(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3320/215338655.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Reshape to fit the network input (channel last)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# How data should be structured\n",
    "num_rows = 40\n",
    "num_columns = 174 \n",
    "num_channels = 1\n",
    "\n",
    "# Reshape to fit the network input (channel last)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns, num_channels)\n",
    "#X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "# Total number of labels to predict (equal to the network output nodes)\n",
    "num_labels = y_train_encoded.shape[1]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f311e898f88d701a4318adb1e80a52632798689d0f8676edc64176ab2d7516a8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
